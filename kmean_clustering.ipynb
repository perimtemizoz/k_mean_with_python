{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Algorithm \n",
    "\n",
    "## Install necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tslearn in ./opt/anaconda3/lib/python3.9/site-packages (0.5.2)\n",
      "Requirement already satisfied: Cython in ./opt/anaconda3/lib/python3.9/site-packages (from tslearn) (0.29.24)\n",
      "Requirement already satisfied: scikit-learn in ./opt/anaconda3/lib/python3.9/site-packages (from tslearn) (0.24.2)\n",
      "Requirement already satisfied: joblib in ./opt/anaconda3/lib/python3.9/site-packages (from tslearn) (1.1.0)\n",
      "Requirement already satisfied: scipy in ./opt/anaconda3/lib/python3.9/site-packages (from tslearn) (1.7.1)\n",
      "Requirement already satisfied: numpy in ./opt/anaconda3/lib/python3.9/site-packages (from tslearn) (1.20.3)\n",
      "Requirement already satisfied: numba in ./opt/anaconda3/lib/python3.9/site-packages (from tslearn) (0.54.1)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in ./opt/anaconda3/lib/python3.9/site-packages (from numba->tslearn) (0.37.0)\n",
      "Requirement already satisfied: setuptools in ./opt/anaconda3/lib/python3.9/site-packages (from numba->tslearn) (58.0.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->tslearn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tslearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Native libraries\n",
    "import os\n",
    "import math\n",
    "\n",
    "# Essential Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Algorithms\n",
    "from tslearn.barycenters import dtw_barycenter_averaging\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTkec6cAMzRy"
   },
   "source": [
    "## Read data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "bTkec6cAMzRy"
   },
   "outputs": [],
   "source": [
    "directory = '/Users/perimtemizoz/Desktop/Doktar/Doktar_Case/point_data/'\n",
    "\n",
    "mySeries = []\n",
    "namesofMySeries = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        df = pd.read_csv(directory+filename)\n",
    "        df = df.loc[:,[\"Time\",\"Relative Humidity\",\"Temperature\"]]\n",
    "        df.sort_index(inplace=True)\n",
    "        mySeries.append(df)\n",
    "        namesofMySeries.append(filename[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "KYtvqe_bYn4S"
   },
   "outputs": [],
   "source": [
    "def stringToDate(frame):\n",
    "    frame['Time'] = pd.to_datetime(frame['Time'])\n",
    "    frame['Hour'] = frame['Time'].apply(lambda time: time.hour)\n",
    "    frame['Month'] = frame['Time'].apply(lambda time: time.month)\n",
    "    frame['Week'] = frame['Time'].apply(lambda time: time.dayofweek)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Feature \n",
    "\n",
    "Hourly temperature and relative humidity data are transformed to monthly mean as a new feature. \n",
    "\\\n",
    "\\\n",
    "In order to make a cluster,  \n",
    "\n",
    "I wanted to bring these data together in a common feature, so it makes sense to separate them *monthly* or *seasonally*, since hourly data cannot be a common feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "53KAAnt5M4OP"
   },
   "outputs": [],
   "source": [
    "def getMean(mySeries):\n",
    "    temp_data = []\n",
    "    for i in range(len(mySeries)):\n",
    "      data = stringToDate(mySeries[i])\n",
    "      data = data.set_index(\"Time\")\n",
    "      df_column = ['Temperature', 'Relative Humidity']\n",
    "      df_monthly_mean = data[df_column].resample(\"MS\").mean() #MS-YEAR Starting\n",
    "      #df_year_mean=mySeries[i].resample(\"YS\").mean() #YS-YEAR Starting\n",
    "      temp_data.append(df_monthly_mean)\n",
    "    return temp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cAhSAjpANglc",
    "outputId": "2a0e5a6e-2aa9-42fe-c702-ccfd30d9609f"
   },
   "outputs": [],
   "source": [
    "mean_calculated_frames = getMean(mySeries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling \n",
    "\n",
    "MinMax Scaling is a case where data takes values between **0 and 1**.\n",
    "\n",
    "Here the distribution is similar to the distribution of the data.\n",
    "\\\n",
    "There is a sensitivity to the outlier data called *outlier* here, so it may not perform well in a situation where these values are high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Fy51zeTJ9zzh"
   },
   "outputs": [],
   "source": [
    "for i in range(len(mean_calculated_frames)):\n",
    "    scaler = MinMaxScaler()\n",
    "    mean_calculated_frames[i] = MinMaxScaler().fit_transform(mean_calculated_frames[i])\n",
    "    mean_calculated_frames[i]= mean_calculated_frames[i].reshape(len(mean_calculated_frames[i]),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means\n",
    "A good rule of thumb is choosing k as the square root of the number of points in the training data set in kMeans\n",
    "In time series analysis, Dynamic Time Warping is used to compare the similarity or calculate the distance between two arrays or time series with different length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "TKu75-g0AwBO"
   },
   "outputs": [],
   "source": [
    "cluster_count = math.ceil(math.sqrt(len(mean_calculated_frames))) \n",
    "\n",
    "km = TimeSeriesKMeans(n_clusters=cluster_count, metric=\"dtw\")\n",
    "\n",
    "labels = km.fit_predict(mean_calculated_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment \n",
    "\n",
    "### Why K-means \n",
    "\\\n",
    "**1**- Simple to implement \n",
    "\\\n",
    "**2**- Scales to large data sets}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "\n",
    "K-means create 3 cluster based on montly mean temperature and relative humidity for 15 station. \n",
    "\\\n",
    "**As I understand from clustering below, It separated the points that are close to each other in the same clusters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Series</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>point_10</th>\n",
       "      <td>Cluster 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point_6</th>\n",
       "      <td>Cluster 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point_7</th>\n",
       "      <td>Cluster 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point_1</th>\n",
       "      <td>Cluster 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point_3</th>\n",
       "      <td>Cluster 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point_5</th>\n",
       "      <td>Cluster 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point_4</th>\n",
       "      <td>Cluster 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point_2</th>\n",
       "      <td>Cluster 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point_13</th>\n",
       "      <td>Cluster 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point_9</th>\n",
       "      <td>Cluster 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point_8</th>\n",
       "      <td>Cluster 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point_12</th>\n",
       "      <td>Cluster 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point_11</th>\n",
       "      <td>Cluster 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point_14</th>\n",
       "      <td>Cluster 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point_15</th>\n",
       "      <td>Cluster 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cluster\n",
       "Series             \n",
       "point_10  Cluster 0\n",
       "point_6   Cluster 0\n",
       "point_7   Cluster 0\n",
       "point_1   Cluster 0\n",
       "point_3   Cluster 0\n",
       "point_5   Cluster 1\n",
       "point_4   Cluster 1\n",
       "point_2   Cluster 1\n",
       "point_13  Cluster 2\n",
       "point_9   Cluster 2\n",
       "point_8   Cluster 2\n",
       "point_12  Cluster 3\n",
       "point_11  Cluster 3\n",
       "point_14  Cluster 3\n",
       "point_15  Cluster 3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fancy_names_for_labels = [f\"Cluster {label}\" for label in labels]\n",
    "pd.DataFrame(zip(namesofMySeries,fancy_names_for_labels),columns=[\"Series\",\"Cluster\"]).sort_values(by=\"Cluster\").set_index(\"Series\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
